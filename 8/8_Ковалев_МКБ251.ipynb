{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade scapy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13f9ab3",
   "metadata": {},
   "source": [
    "#### **Этап 1. Изучение Scapy**\n",
    "1. Изучите основы работы с Scapy.\n",
    "2. Настройте Scapy для перехвата HTTP-трафика, используйте скрипт scapy для отправки HTTP-запросов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0d6a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "from scapy.all import sniff, load_layer\n",
    "from scapy.layers.http import HTTPRequest, HTTPResponse\n",
    "from scapy.packet import Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0edcae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем слой HTTP для корректного разбора пакетов Scapy\n",
    "load_layer(\"http\")\n",
    "\n",
    "# Настройка логирования\n",
    "file_log = logging.FileHandler(f'{datetime.now().date()}_log.log')\n",
    "console_out = logging.StreamHandler()\n",
    "    \n",
    "logging.basicConfig(handlers=(file_log, console_out), \n",
    "                        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                        level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Список типичных сигнатур XSS для поиска в трафике (Этап 3, Примеры XSS) [cite: 38, 39, 40]\n",
    "XSS_PAYLOADS = [\n",
    "    \"<script>alert('XSS')</script>\",\n",
    "    \"<img src=\\\"nonexistent.jpg\\\" onerror=\\\"alert('XSS')\\\">\",\n",
    "    \"alert('XSS')\",\n",
    "    \"javascript:alert\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e42f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_xss_signature(content: str) -> bool:\n",
    "    \"\"\"\n",
    "    Проверяет вхождение известных XSS-сигнатур в контент.\n",
    "    \n",
    "    Args:\n",
    "        content (str): Анализируемая строка (тело запроса или ответа).\n",
    "    \n",
    "    Returns:\n",
    "        bool: True, если найден XSS паттерн.\n",
    "    \"\"\"\n",
    "    for payload in XSS_PAYLOADS:\n",
    "        # Проверяем наличие пейлоада или его URL-кодированных вариаций (упрощенно)\n",
    "        if payload in content:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6079b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_decode(byte_data: bytes) -> str:\n",
    "    \"\"\"\n",
    "    Безопасно декодирует байты в строку, игнорируя ошибки.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return byte_data.decode('utf-8', errors='ignore')\n",
    "    except Exception:\n",
    "        return str(byte_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8253c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _analyze_request(packet):\n",
    "    \"\"\"\n",
    "    Анализирует HTTP-запрос. Выводит метод, хост и путь.\n",
    "    Ищет попытки инъекции XSS в отправляемых данных.\n",
    "    \n",
    "    Args:\n",
    "        packet: Объект пакета Scapy с слоем HTTPRequest.\n",
    "    \"\"\"\n",
    "    url = packet[HTTPRequest].Host.decode() + packet[HTTPRequest].Path.decode()\n",
    "    method = packet[HTTPRequest].Method.decode()\n",
    "    \n",
    "    log_msg = f\"[>>] REQUEST: {method} {url}\"\n",
    "    \n",
    "    # Проверка наличия сырых данных (тело запроса, параметры)\n",
    "    if packet.haslayer(Raw):\n",
    "        load = _safe_decode(packet[Raw].load)\n",
    "        if _check_xss_signature(load):\n",
    "            log_msg += f\"\\n    [!] ВНИМАНИЕ: Обнаружен XSS-пейлоад в запросе:\\n    {load}\"\n",
    "            \n",
    "    logger.info(log_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625e00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _analyze_response(packet):\n",
    "    \"\"\"\n",
    "    Анализирует HTTP-ответ. Выводит статус.\n",
    "    Ищет следы отраженной (Reflected) XSS атаки в ответе сервера.\n",
    "    Это необходимо для выполнения Этапа 4[cite: 42, 43].\n",
    "    \n",
    "    Args:\n",
    "        packet: Объект пакета Scapy с слоем HTTPResponse.\n",
    "    \"\"\"\n",
    "    status = packet[HTTPResponse].Status_Code.decode() if packet[HTTPResponse].Status_Code else \"Unknown\"\n",
    "    \n",
    "    log_msg = f\"[<<] RESPONSE: Status {status}\"\n",
    "\n",
    "    if packet.haslayer(Raw):\n",
    "        load = _safe_decode(packet[Raw].load)\n",
    "        # Если пейлоад найден в ответе, значит сервер вернул его без санитизации (успешная XSS)\n",
    "        if _check_xss_signature(load):\n",
    "            log_msg += f\"\\n    [!!!] КРИТИЧНО: Обнаружено отражение XSS в ответе (Уязвимость подтверждена):\\n    {load[:200]}...\" \n",
    "            \n",
    "    logger.info(log_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e720fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_packet(packet):\n",
    "    \"\"\"\n",
    "    Callback-функция для обработки каждого перехваченного пакета.\n",
    "    Анализирует HTTP запросы и ответы на наличие подозрительных данных.\n",
    "    \n",
    "    Args:\n",
    "        packet: Объект пакета Scapy.\n",
    "    \"\"\"\n",
    "    # Проверяем наличие слоя HTTPRequest (Исходящий трафик)\n",
    "    if packet.haslayer(HTTPRequest):\n",
    "        _analyze_request(packet)\n",
    "\n",
    "    # Проверяем наличие слоя HTTPResponse (Входящий трафик)\n",
    "    elif packet.haslayer(HTTPResponse):\n",
    "        _analyze_response(packet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20532d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_sniffer(interface: str = None):\n",
    "    \"\"\"\n",
    "    Запускает сниффер Scapy.\n",
    "    \n",
    "    Args:\n",
    "        interface (str): Название сетевого интерфейса (например, 'eth0', 'Wi-Fi').\n",
    "                         Если None, Scapy выберет интерфейс по умолчанию.\n",
    "    \"\"\"\n",
    "    print(f\"[*] Запуск перехвата HTTP трафика на интерфейсе: {interface or 'Default'}\")\n",
    "    print(\"[*] Нажмите Ctrl+C для остановки.\")\n",
    "    \n",
    "    # Фильтр 'tcp port 80' важен, так как Google Gruyere обычно работает по HTTP (не HTTPS)\n",
    "    # Это соответствует заданию по сбору трафика[cite: 31].\n",
    "    sniff(\n",
    "        iface=interface,\n",
    "        filter=\"tcp port 80\",\n",
    "        prn=process_packet,\n",
    "        store=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9863f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    start_sniffer()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n[*] Перехват остановлен пользователем.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
